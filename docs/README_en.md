# Movable Voice Print

<p align="center">
  <a href="./README_en.md"><img src="https://img.shields.io/badge/English-0078D4?style=flat&logo=google-translate&logoColor=white" alt="English"></a>
  <a href="../README.md"><img src="https://img.shields.io/badge/ä¸­æ–‡-FF0000?style=flat&logo=google-translate&logoColor=white" alt="ä¸­æ–‡"></a>
</p>

## ğŸŒŸ Project Overview  
This tool uses speech recognition (Whisper) to extract word/character-level timestamps from audio, splits audio segments based on time intervals, then randomly reorganizes them to generate new audio.

## ğŸš€ Core Features  
1. **Multilingual Word Segmentation**: Powered by Whisper model, supports 100+ languages (Chinese/English/Japanese, etc.), precisely identifying word/character time intervals.  
2. **Lossless Audio Recomposition**: Randomly rearranges original audio fragments while preserving speaker's voice characteristics and intonation.  
3. **Automated Workflow**: One-click processing for full pipeline - "Speech Recognition â†’ Splitting â†’ Recomposition".  

## ğŸ“¦ Requirements  
- **OS**: Windows/macOS/Linux  
- **Dependencies**:  
  - Python 3.8-3.10  
  - PyTorch  
  - Whisper  
  - pydub  

## ğŸ› ï¸ Installation  
1. **Clone Repository**  
   ```bash  
   git clone https://github.com/DPCau/movable-voice-print.git  
   ```  
2. **Create Virtual Environment**  
   ```bash  
   uv venv --python 3.9  
   source .venv/bin/activate  
   ```  

3. **Install Python Dependencies**  
   ```bash  
   pip install -r requirements.txt  
   ```  

4. **Install FFmpeg**  
   - **Windows**: Download from [FFmpeg Official](https://ffmpeg.org/), add to PATH.  
   - **macOS**: `brew install ffmpeg`  
   - **Linux**: `sudo apt-get install ffmpeg`  

## ğŸ“– Usage Guide  
### 1. Prepare Input Audio  
- Supported Formats: MP3/WAV  
- Recommendation: â‰¤30min duration, clear speech (background noise may reduce accuracy).  

### 2. Run Script  
```python  
python main.py --input input.mp3  
```  

### 3. Optional Parameters  
| Parameter       | Description                                                                 |  
|-----------------|-----------------------------------------------------------------------------|  
| `--input`       | Input audio path (required)                                                 |  
| `--output`      | Output path (default: output_audio.mp3)                                     |  
| `--model`       | Whisper model size (options: tiny/base/small/medium/large, default: base)   |  
| `--language`    | Force language detection (e.g., zh/en/jp, default: english). Affects text splitting only. |  
| `--format`      | Output format (options: mp3/wav, default: mp3)                             |  
| `--device`      | Compute device (options: cpu/cuda, default: cpu)                            |  

## ğŸ“˜ Example Workflow  
1. **Input Audio**:  
   ```  
   input.mp3 (Content: "[Sun Xiaochuan]ä¸è¦è¯´åºŸè¯æˆ‘ä¸å–œæ¬¢åˆ«äººè¯´åºŸè¯.<Don't talk nonsense. I hate people talking nonsense.>")  
   ```  

2. **Timestamp Recognition**:  
   ```json  
   [
      {"text": "ä¸è¦", "start": 0.0, "end": 0.26}, 
      {"text": "è¯´", "start": 0.26, "end": 0.5}, 
      {"text": "åºŸ", "start": 0.5, "end": 0.68}, 
      {"text": "è¯", "start": 0.68, "end": 0.84}, 
      {"text": "æˆ‘ä¸", "start": 0.84, "end": 1.14}, 
      {"text": "å–œæ¬¢", "start": 1.14, "end": 1.48}, 
      {"text": "åˆ«", "start": 1.48, "end": 1.72}, 
      {"text": "äºº", "start": 1.72, "end": 1.82}, 
      {"text": "è¯´", "start": 1.82, "end": 1.98}, 
      {"text": "åºŸ", "start": 1.98, "end": 2.18}, 
      {"text": "è¯", "start": 2.18, "end": 2.42}
   ]
   ```  

3. **Recomposed Output**:  
   ```  
   output_audio.mp3 (Content: "[Sun Xiaochuan] è¯´è¦åºŸè¯æˆ‘åºŸå–œä¸è¯´æ¬¢ä¸äººåˆ«è¯.")  
   ```  

## ğŸ§ª Accuracy & Optimization  
**Speech Recognition Accuracy**:  
Recommend using `medium` or `large` models for better timestamp accuracy in Chinese and other languages.

## ğŸ“œ License  
MIT